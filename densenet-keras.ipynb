{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets.cifar10 import load_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet / CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path = 'data/cifar-10-batches-py'\n",
    "    num_train_samples = 50000\n",
    "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_batch(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        x_train[(i - 1) * 10000: i * 10000, :, :, :] = data\n",
    "        y_train[(i - 1) * 10000: i * 10000] = labels\n",
    "    x_test, y_test = load_batch(os.path.join(path, 'test_batch'))\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0604030128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0608dd2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255.\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization(mode=0, axis=-1)(x)\n",
    "def relu_bn(x): return relu(bn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, nf, sz, wd, p):\n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same', \n",
    "                          W_regularizer=l2(wd))(x)\n",
    "    return dropout(x,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck: x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_block(x, compression=1.0, p=None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x)\n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2, 2), strides=(2, 2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck: nb_layers //= 2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        x = merge([x,b], mode='concat', concat_axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the DenseNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nb_classes: number of classes\n",
    "- img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "- depth: number or layers\n",
    "- nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "- growth_rate: number of filters to add per dense block\n",
    "- nb_filter:  initial number of filters\n",
    "- bottleneck: add bottleneck blocks\n",
    "- reduction:  reduction factor of transition blocks.  Note : reduction value is inverted to compute compression\n",
    "- p: dropout rate\n",
    "- wd: weight decay\n",
    "- activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'. Note that if sigmoid is used, classes must be 1.\n",
    "\n",
    "Returns: keras tensor with nb_layers of conv_block appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, \n",
    "     growth_rate=12, nb_filter=16, bottleneck=False, compression=0.0, p=None, wd=0):\n",
    "\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i,block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        if i != len(nb_layers)-1:\n",
    "            x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "\n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation='softmax', W_regularizer=l2(wd))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=-1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \"\"\"\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(104, (1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(148, (1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "x = create_dense_net(10, img_input, depth=100, nb_filter=16, compression=0.5, \n",
    "                     bottleneck=True, p=0.2, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 32, 32, 16)    448         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 32, 32, 16)    64          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 32, 16)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 32, 32, 48)    816         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32, 32, 48)    0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 32, 32, 48)    192         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 32, 48)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 32, 32, 12)    5196        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 32, 32, 12)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 32, 32, 28)    0           conv2d_2[0][0]                   \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 32, 32, 28)    112         merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 32, 32, 28)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 32, 32, 48)    1392        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 32, 32, 48)    0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 32, 32, 48)    192         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 32, 32, 48)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 32, 32, 12)    5196        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 32, 32, 12)    0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 32, 32, 40)    0           merge_1[0][0]                    \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 32, 32, 40)    160         merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 32, 32, 40)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 32, 32, 48)    1968        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32, 32, 48)    0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 32, 32, 48)    192         dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32, 32, 48)    0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 32, 32, 12)    5196        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 32, 32, 12)    0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 32, 32, 52)    0           merge_2[0][0]                    \n",
      "                                                                   dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 32, 32, 52)    208         merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 32, 32, 52)    0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 32, 32, 48)    2544        activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 32, 32, 48)    0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 32, 32, 48)    192         dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 32, 32, 48)    0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 32, 32, 12)    5196        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 32, 32, 12)    0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 32, 32, 64)    0           merge_3[0][0]                    \n",
      "                                                                   dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 32, 32, 64)    256         merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 32, 32, 64)    0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 32, 32, 48)    3120        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 32, 32, 48)    0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 32, 32, 48)    192         dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 32, 32, 48)    0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 32, 32, 12)    5196        activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 32, 32, 12)    0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 32, 32, 76)    0           merge_4[0][0]                    \n",
      "                                                                   dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 32, 32, 76)    304         merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 32, 32, 76)    0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 32, 32, 48)    3696        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 32, 32, 48)    0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 32, 32, 48)    192         dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 32, 32, 48)    0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 32, 32, 12)    5196        activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 32, 32, 12)    0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 32, 32, 88)    0           merge_5[0][0]                    \n",
      "                                                                   dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 32, 32, 88)    352         merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 32, 32, 88)    0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 32, 32, 48)    4272        activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 32, 32, 48)    0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 32, 32, 48)    192         dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 32, 32, 48)    0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 32, 32, 12)    5196        activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 32, 32, 12)    0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 32, 32, 100)   0           merge_6[0][0]                    \n",
      "                                                                   dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 32, 32, 100)   400         merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 32, 32, 100)   0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 32, 32, 48)    4848        activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 32, 32, 48)    0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 32, 32, 48)    192         dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 32, 32, 48)    0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 32, 32, 12)    5196        activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 32, 32, 12)    0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 32, 32, 112)   0           merge_7[0][0]                    \n",
      "                                                                   dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 32, 32, 112)   448         merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 32, 32, 112)   0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 32, 32, 48)    5424        activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 32, 32, 48)    0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 32, 32, 48)    192         dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 32, 32, 48)    0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 32, 32, 12)    5196        activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 32, 32, 12)    0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 32, 32, 124)   0           merge_8[0][0]                    \n",
      "                                                                   dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 32, 32, 124)   496         merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 32, 32, 124)   0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 32, 32, 48)    6000        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 32, 32, 48)    0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 32, 32, 48)    192         dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 32, 32, 48)    0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 32, 32, 12)    5196        activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 32, 32, 12)    0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 32, 32, 136)   0           merge_9[0][0]                    \n",
      "                                                                   dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 32, 32, 136)   544         merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 32, 32, 136)   0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 32, 32, 48)    6576        activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 32, 32, 48)    0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 32, 32, 48)    192         dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 32, 32, 48)    0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 32, 32, 12)    5196        activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 32, 32, 12)    0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 32, 32, 148)   0           merge_10[0][0]                   \n",
      "                                                                   dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 32, 32, 148)   592         merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 32, 32, 148)   0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 32, 32, 48)    7152        activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 32, 32, 48)    0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 32, 32, 48)    192         dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 32, 32, 48)    0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 32, 32, 12)    5196        activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 32, 32, 12)    0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 32, 32, 160)   0           merge_11[0][0]                   \n",
      "                                                                   dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 32, 32, 160)   640         merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 32, 32, 160)   0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 32, 32, 48)    7728        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 32, 32, 48)    0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 32, 32, 48)    192         dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 32, 32, 48)    0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 32, 32, 12)    5196        activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 32, 32, 12)    0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 32, 32, 172)   0           merge_12[0][0]                   \n",
      "                                                                   dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 32, 32, 172)   688         merge_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 32, 32, 172)   0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 32, 32, 48)    8304        activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 32, 32, 48)    0           conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 32, 32, 48)    192         dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 32, 32, 48)    0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 32, 32, 12)    5196        activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 32, 32, 12)    0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 32, 32, 184)   0           merge_13[0][0]                   \n",
      "                                                                   dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 32, 32, 184)   736         merge_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 32, 32, 184)   0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 32, 32, 48)    8880        activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 32, 32, 48)    0           conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 32, 32, 48)    192         dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 32, 32, 48)    0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 32, 32, 12)    5196        activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 32, 32, 12)    0           conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 32, 32, 196)   0           merge_14[0][0]                   \n",
      "                                                                   dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 32, 32, 196)   784         merge_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 32, 32, 196)   0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 32, 32, 48)    9456        activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 32, 32, 48)    0           conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 32, 32, 48)    192         dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 32, 32, 48)    0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 32, 32, 12)    5196        activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 32, 32, 12)    0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 32, 32, 208)   0           merge_15[0][0]                   \n",
      "                                                                   dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 32, 32, 208)   832         merge_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 32, 32, 208)   0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 32, 32, 104)   21736       activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 32, 32, 104)   0           conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 16, 16, 104)   0           dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 16, 16, 104)   416         average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 16, 16, 104)   0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 16, 16, 48)    5040        activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 16, 16, 48)    0           conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 16, 16, 48)    192         dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 16, 16, 48)    0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 16, 16, 12)    5196        activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 16, 16, 12)    0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_17 (Merge)                 (None, 16, 16, 116)   0           average_pooling2d_1[0][0]        \n",
      "                                                                   dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 16, 16, 116)   464         merge_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 16, 16, 116)   0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 16, 16, 48)    5616        activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 16, 16, 48)    0           conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 16, 16, 48)    192         dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 16, 16, 48)    0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 16, 16, 12)    5196        activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 16, 16, 12)    0           conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_18 (Merge)                 (None, 16, 16, 128)   0           merge_17[0][0]                   \n",
      "                                                                   dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 16, 16, 128)   512         merge_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 16, 16, 128)   0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 16, 16, 48)    6192        activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 16, 16, 48)    0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 16, 16, 48)    192         dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 16, 16, 48)    0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 16, 16, 12)    5196        activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 16, 16, 12)    0           conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_19 (Merge)                 (None, 16, 16, 140)   0           merge_18[0][0]                   \n",
      "                                                                   dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 16, 16, 140)   560         merge_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 16, 16, 140)   0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 16, 16, 48)    6768        activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 16, 16, 48)    0           conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 16, 16, 48)    192         dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 16, 16, 48)    0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 16, 16, 12)    5196        activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 16, 16, 12)    0           conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_20 (Merge)                 (None, 16, 16, 152)   0           merge_19[0][0]                   \n",
      "                                                                   dropout_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 16, 16, 152)   608         merge_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 16, 16, 152)   0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 16, 16, 48)    7344        activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)             (None, 16, 16, 48)    0           conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 16, 16, 48)    192         dropout_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 16, 16, 48)    0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 16, 16, 12)    5196        activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)             (None, 16, 16, 12)    0           conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_21 (Merge)                 (None, 16, 16, 164)   0           merge_20[0][0]                   \n",
      "                                                                   dropout_43[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 16, 16, 164)   656         merge_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 16, 16, 164)   0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 16, 16, 48)    7920        activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)             (None, 16, 16, 48)    0           conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 16, 16, 48)    192         dropout_44[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 16, 16, 48)    0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 16, 16, 12)    5196        activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)             (None, 16, 16, 12)    0           conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_22 (Merge)                 (None, 16, 16, 176)   0           merge_21[0][0]                   \n",
      "                                                                   dropout_45[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 16, 16, 176)   704         merge_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 16, 16, 176)   0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 16, 16, 48)    8496        activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 16, 16, 48)    0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 16, 16, 48)    192         dropout_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 16, 16, 48)    0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 16, 16, 12)    5196        activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 16, 16, 12)    0           conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_23 (Merge)                 (None, 16, 16, 188)   0           merge_22[0][0]                   \n",
      "                                                                   dropout_47[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 16, 16, 188)   752         merge_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 16, 16, 188)   0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 16, 16, 48)    9072        activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 16, 16, 48)    0           conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 16, 16, 48)    192         dropout_48[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 16, 16, 48)    0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 16, 16, 12)    5196        activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 16, 16, 12)    0           conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_24 (Merge)                 (None, 16, 16, 200)   0           merge_23[0][0]                   \n",
      "                                                                   dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 16, 16, 200)   800         merge_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 16, 16, 200)   0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 16, 16, 48)    9648        activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 16, 16, 48)    0           conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 16, 16, 48)    192         dropout_50[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 16, 16, 48)    0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 16, 16, 12)    5196        activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 16, 16, 12)    0           conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_25 (Merge)                 (None, 16, 16, 212)   0           merge_24[0][0]                   \n",
      "                                                                   dropout_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 16, 16, 212)   848         merge_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 16, 16, 212)   0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 16, 16, 48)    10224       activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 16, 16, 48)    0           conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, 16, 16, 48)    192         dropout_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 16, 16, 48)    0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 16, 16, 12)    5196        activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 16, 16, 12)    0           conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_26 (Merge)                 (None, 16, 16, 224)   0           merge_25[0][0]                   \n",
      "                                                                   dropout_53[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, 16, 16, 224)   896         merge_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 16, 16, 224)   0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 16, 16, 48)    10800       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 16, 16, 48)    0           conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, 16, 16, 48)    192         dropout_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 16, 16, 48)    0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 16, 16, 12)    5196        activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 16, 16, 12)    0           conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_27 (Merge)                 (None, 16, 16, 236)   0           merge_26[0][0]                   \n",
      "                                                                   dropout_55[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, 16, 16, 236)   944         merge_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 16, 16, 236)   0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 16, 16, 48)    11376       activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 16, 16, 48)    0           conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 16, 16, 48)    192         dropout_56[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 16, 16, 48)    0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 16, 16, 12)    5196        activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 16, 16, 12)    0           conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_28 (Merge)                 (None, 16, 16, 248)   0           merge_27[0][0]                   \n",
      "                                                                   dropout_57[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 16, 16, 248)   992         merge_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 16, 16, 248)   0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 16, 16, 48)    11952       activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)             (None, 16, 16, 48)    0           conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 16, 16, 48)    192         dropout_58[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 16, 16, 48)    0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, 16, 16, 12)    5196        activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)             (None, 16, 16, 12)    0           conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_29 (Merge)                 (None, 16, 16, 260)   0           merge_28[0][0]                   \n",
      "                                                                   dropout_59[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 16, 16, 260)   1040        merge_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 16, 16, 260)   0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, 16, 16, 48)    12528       activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)             (None, 16, 16, 48)    0           conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 16, 16, 48)    192         dropout_60[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 16, 16, 48)    0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, 16, 16, 12)    5196        activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 16, 16, 12)    0           conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_30 (Merge)                 (None, 16, 16, 272)   0           merge_29[0][0]                   \n",
      "                                                                   dropout_61[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 16, 16, 272)   1088        merge_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 16, 16, 272)   0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, 16, 16, 48)    13104       activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 16, 16, 48)    0           conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 16, 16, 48)    192         dropout_62[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 16, 16, 48)    0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, 16, 16, 12)    5196        activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)             (None, 16, 16, 12)    0           conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_31 (Merge)                 (None, 16, 16, 284)   0           merge_30[0][0]                   \n",
      "                                                                   dropout_63[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 16, 16, 284)   1136        merge_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 16, 16, 284)   0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, 16, 16, 48)    13680       activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 16, 16, 48)    0           conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 16, 16, 48)    192         dropout_64[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 16, 16, 48)    0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, 16, 16, 12)    5196        activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 16, 16, 12)    0           conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_32 (Merge)                 (None, 16, 16, 296)   0           merge_31[0][0]                   \n",
      "                                                                   dropout_65[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 16, 16, 296)   1184        merge_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 16, 16, 296)   0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, 16, 16, 148)   43956       activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)             (None, 16, 16, 148)   0           conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 8, 8, 148)     0           dropout_66[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 8, 8, 148)     592         average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 8, 8, 148)     0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 8, 8, 48)      7152        activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 8, 8, 48)      0           conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 8, 8, 48)      192         dropout_67[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 8, 8, 48)      0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 8, 8, 12)      5196        activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 8, 8, 12)      0           conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_33 (Merge)                 (None, 8, 8, 160)     0           average_pooling2d_2[0][0]        \n",
      "                                                                   dropout_68[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 8, 8, 160)     640         merge_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 8, 8, 160)     0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 8, 8, 48)      7728        activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 8, 8, 48)      0           conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 8, 8, 48)      192         dropout_69[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 8, 8, 48)      0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 8, 8, 12)      5196        activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 8, 8, 12)      0           conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_34 (Merge)                 (None, 8, 8, 172)     0           merge_33[0][0]                   \n",
      "                                                                   dropout_70[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 8, 8, 172)     688         merge_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 8, 8, 172)     0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 8, 8, 48)      8304        activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 8, 8, 48)      0           conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 8, 8, 48)      192         dropout_71[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 8, 8, 48)      0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 8, 8, 12)      5196        activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 8, 8, 12)      0           conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_35 (Merge)                 (None, 8, 8, 184)     0           merge_34[0][0]                   \n",
      "                                                                   dropout_72[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 8, 8, 184)     736         merge_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 8, 8, 184)     0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 8, 8, 48)      8880        activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)             (None, 8, 8, 48)      0           conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 8, 8, 48)      192         dropout_73[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 8, 8, 48)      0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 8, 8, 12)      5196        activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)             (None, 8, 8, 12)      0           conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_36 (Merge)                 (None, 8, 8, 196)     0           merge_35[0][0]                   \n",
      "                                                                   dropout_74[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 8, 8, 196)     784         merge_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 8, 8, 196)     0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 8, 8, 48)      9456        activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)             (None, 8, 8, 48)      0           conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 8, 8, 48)      192         dropout_75[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 8, 8, 48)      0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 8, 8, 12)      5196        activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)             (None, 8, 8, 12)      0           conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_37 (Merge)                 (None, 8, 8, 208)     0           merge_36[0][0]                   \n",
      "                                                                   dropout_76[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 8, 8, 208)     832         merge_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 8, 8, 208)     0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 8, 8, 48)      10032       activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)             (None, 8, 8, 48)      0           conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 8, 8, 48)      192         dropout_77[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, 8, 8, 48)      0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 8, 8, 12)      5196        activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)             (None, 8, 8, 12)      0           conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_38 (Merge)                 (None, 8, 8, 220)     0           merge_37[0][0]                   \n",
      "                                                                   dropout_78[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 8, 8, 220)     880         merge_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, 8, 8, 220)     0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 8, 8, 48)      10608       activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)             (None, 8, 8, 48)      0           conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 8, 8, 48)      192         dropout_79[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, 8, 8, 48)      0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 8, 8, 12)      5196        activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)             (None, 8, 8, 12)      0           conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_39 (Merge)                 (None, 8, 8, 232)     0           merge_38[0][0]                   \n",
      "                                                                   dropout_80[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 8, 8, 232)     928         merge_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, 8, 8, 232)     0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 8, 8, 48)      11184       activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)             (None, 8, 8, 48)      0           conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 8, 8, 48)      192         dropout_81[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 8, 8, 48)      0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 8, 8, 12)      5196        activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)             (None, 8, 8, 12)      0           conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_40 (Merge)                 (None, 8, 8, 244)     0           merge_39[0][0]                   \n",
      "                                                                   dropout_82[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 8, 8, 244)     976         merge_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 8, 8, 244)     0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 8, 8, 48)      11760       activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)             (None, 8, 8, 48)      0           conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 8, 8, 48)      192         dropout_83[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, 8, 8, 48)      0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 8, 8, 12)      5196        activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)             (None, 8, 8, 12)      0           conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_41 (Merge)                 (None, 8, 8, 256)     0           merge_40[0][0]                   \n",
      "                                                                   dropout_84[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 8, 8, 256)     1024        merge_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, 8, 8, 256)     0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 8, 8, 48)      12336       activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)             (None, 8, 8, 48)      0           conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 8, 8, 48)      192         dropout_85[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 8, 8, 48)      0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 8, 8, 12)      5196        activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)             (None, 8, 8, 12)      0           conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_42 (Merge)                 (None, 8, 8, 268)     0           merge_41[0][0]                   \n",
      "                                                                   dropout_86[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 8, 8, 268)     1072        merge_42[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 8, 8, 268)     0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 8, 8, 48)      12912       activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)             (None, 8, 8, 48)      0           conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 8, 8, 48)      192         dropout_87[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 8, 8, 48)      0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 8, 8, 12)      5196        activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)             (None, 8, 8, 12)      0           conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_43 (Merge)                 (None, 8, 8, 280)     0           merge_42[0][0]                   \n",
      "                                                                   dropout_88[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 8, 8, 280)     1120        merge_43[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 8, 8, 280)     0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 8, 8, 48)      13488       activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)             (None, 8, 8, 48)      0           conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 8, 8, 48)      192         dropout_89[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 8, 8, 48)      0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 8, 8, 12)      5196        activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)             (None, 8, 8, 12)      0           conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_44 (Merge)                 (None, 8, 8, 292)     0           merge_43[0][0]                   \n",
      "                                                                   dropout_90[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 8, 8, 292)     1168        merge_44[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 8, 8, 292)     0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 8, 8, 48)      14064       activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)             (None, 8, 8, 48)      0           conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 8, 8, 48)      192         dropout_91[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 8, 8, 48)      0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 8, 8, 12)      5196        activation_92[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)             (None, 8, 8, 12)      0           conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_45 (Merge)                 (None, 8, 8, 304)     0           merge_44[0][0]                   \n",
      "                                                                   dropout_92[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 8, 8, 304)     1216        merge_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 8, 8, 304)     0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 8, 8, 48)      14640       activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)             (None, 8, 8, 48)      0           conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 8, 8, 48)      192         dropout_93[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 8, 8, 48)      0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 8, 8, 12)      5196        activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)             (None, 8, 8, 12)      0           conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_46 (Merge)                 (None, 8, 8, 316)     0           merge_45[0][0]                   \n",
      "                                                                   dropout_94[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 8, 8, 316)     1264        merge_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 8, 8, 316)     0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 8, 8, 48)      15216       activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)             (None, 8, 8, 48)      0           conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 8, 8, 48)      192         dropout_95[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 8, 8, 48)      0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 8, 8, 12)      5196        activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)             (None, 8, 8, 12)      0           conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_47 (Merge)                 (None, 8, 8, 328)     0           merge_46[0][0]                   \n",
      "                                                                   dropout_96[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 8, 8, 328)     1312        merge_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 8, 8, 328)     0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 8, 8, 48)      15792       activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)             (None, 8, 8, 48)      0           conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 8, 8, 48)      192         dropout_97[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 8, 8, 48)      0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 8, 8, 12)      5196        activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)             (None, 8, 8, 12)      0           conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "merge_48 (Merge)                 (None, 8, 8, 340)     0           merge_47[0][0]                   \n",
      "                                                                   dropout_98[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 8, 8, 340)     1360        merge_48[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 8, 8, 340)     0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 340)           0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            3410        global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 781,470\n",
      "Trainable params: 757,958\n",
      "Non-trainable params: 23,512\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "      optimizer=keras.optimizers.SGD(0.1, 0.9, nesterov=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "561s - loss: 1.9801 - acc: 0.4810 - val_loss: 2.0473 - val_acc: 0.5045\n",
      "Epoch 2/20\n",
      "556s - loss: 1.4368 - acc: 0.6571 - val_loss: 1.8446 - val_acc: 0.5864\n",
      "Epoch 3/20\n",
      "547s - loss: 1.2204 - acc: 0.7122 - val_loss: 1.3181 - val_acc: 0.6696\n",
      "Epoch 4/20\n",
      "556s - loss: 1.0634 - acc: 0.7547 - val_loss: 1.3620 - val_acc: 0.6658\n",
      "Epoch 5/20\n",
      "560s - loss: 0.9536 - acc: 0.7829 - val_loss: 2.6235 - val_acc: 0.4702\n",
      "Epoch 6/20\n",
      "557s - loss: 0.8835 - acc: 0.8025 - val_loss: 2.4969 - val_acc: 0.4981\n",
      "Epoch 7/20\n",
      "551s - loss: 0.8293 - acc: 0.8155 - val_loss: 1.1944 - val_acc: 0.7281\n",
      "Epoch 8/20\n",
      "551s - loss: 0.7949 - acc: 0.8244 - val_loss: 1.1396 - val_acc: 0.7366\n",
      "Epoch 9/20\n",
      "551s - loss: 0.7620 - acc: 0.8340 - val_loss: 1.9196 - val_acc: 0.5916\n",
      "Epoch 10/20\n",
      "551s - loss: 0.7472 - acc: 0.8389 - val_loss: 2.6207 - val_acc: 0.4900\n",
      "Epoch 11/20\n",
      "550s - loss: 0.7251 - acc: 0.8449 - val_loss: 1.4957 - val_acc: 0.6859\n",
      "Epoch 12/20\n",
      "551s - loss: 0.7117 - acc: 0.8503 - val_loss: 1.0381 - val_acc: 0.7751\n",
      "Epoch 13/20\n",
      "552s - loss: 0.7006 - acc: 0.8547 - val_loss: 1.6471 - val_acc: 0.6685\n",
      "Epoch 14/20\n",
      "556s - loss: 0.6945 - acc: 0.8555 - val_loss: 0.9267 - val_acc: 0.8087\n",
      "Epoch 15/20\n",
      "551s - loss: 0.6859 - acc: 0.8592 - val_loss: 1.0987 - val_acc: 0.7642\n",
      "Epoch 16/20\n",
      "550s - loss: 0.6756 - acc: 0.8645 - val_loss: 0.9704 - val_acc: 0.7940\n",
      "Epoch 17/20\n",
      "551s - loss: 0.6730 - acc: 0.8642 - val_loss: 0.9401 - val_acc: 0.7800\n",
      "Epoch 18/20\n",
      "551s - loss: 0.6666 - acc: 0.8700 - val_loss: 0.9759 - val_acc: 0.7830\n",
      "Epoch 19/20\n",
      "550s - loss: 0.6654 - acc: 0.8709 - val_loss: 0.8896 - val_acc: 0.8044\n",
      "Epoch 20/20\n",
      "551s - loss: 0.6617 - acc: 0.8712 - val_loss: 1.1052 - val_acc: 0.7570\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04f8b132b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "550s - loss: 0.5463 - acc: 0.9128 - val_loss: 0.5737 - val_acc: 0.9033\n",
      "Epoch 2/4\n",
      "551s - loss: 0.4833 - acc: 0.9311 - val_loss: 0.5695 - val_acc: 0.9033\n",
      "Epoch 3/4\n",
      "551s - loss: 0.4575 - acc: 0.9366 - val_loss: 0.5590 - val_acc: 0.9051\n",
      "Epoch 4/4\n",
      "550s - loss: 0.4361 - acc: 0.9429 - val_loss: 0.5656 - val_acc: 0.9048\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05ec7caf28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 4, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "\n",
      "Epoch 1/20\n",
      "551s - loss: 0.6589 - acc: 0.8728 - val_loss: 1.3259 - val_acc: 0.6935\n",
      "Epoch 2/20\n",
      "551s - loss: 0.6510 - acc: 0.8766 - val_loss: 0.9672 - val_acc: 0.7880\n",
      "Epoch 3/20\n",
      "551s - loss: 0.6508 - acc: 0.8784 - val_loss: 1.1104 - val_acc: 0.7581\n",
      "Epoch 4/20\n",
      "551s - loss: 0.6462 - acc: 0.8793 - val_loss: 1.0601 - val_acc: 0.7877\n",
      "Epoch 5/20\n",
      "550s - loss: 0.6456 - acc: 0.8816 - val_loss: 0.9799 - val_acc: 0.7876\n",
      "Epoch 6/20\n",
      "551s - loss: 0.6427 - acc: 0.8830 - val_loss: 0.9377 - val_acc: 0.8028\n",
      "Epoch 7/20\n",
      "551s - loss: 0.6409 - acc: 0.8837 - val_loss: 1.8484 - val_acc: 0.5932\n",
      "Epoch 8/20\n",
      "551s - loss: 0.6378 - acc: 0.8831 - val_loss: 1.1806 - val_acc: 0.7420\n",
      "Epoch 9/20\n",
      "550s - loss: 0.6381 - acc: 0.8843 - val_loss: 1.0799 - val_acc: 0.7774\n",
      "Epoch 10/20\n",
      "551s - loss: 0.6344 - acc: 0.8870 - val_loss: 0.9114 - val_acc: 0.8163\n",
      "Epoch 11/20\n",
      "561s - loss: 0.6394 - acc: 0.8858 - val_loss: 0.9710 - val_acc: 0.7982\n",
      "Epoch 12/20\n",
      "560s - loss: 0.6367 - acc: 0.8863 - val_loss: 0.8751 - val_acc: 0.8249\n",
      "Epoch 13/20\n",
      "561s - loss: 0.6230 - acc: 0.8899 - val_loss: 1.2588 - val_acc: 0.7254\n",
      "Epoch 14/20\n",
      "561s - loss: 0.6298 - acc: 0.8895 - val_loss: 0.9942 - val_acc: 0.7801\n",
      "Epoch 15/20\n",
      "560s - loss: 0.6321 - acc: 0.8888 - val_loss: 0.8516 - val_acc: 0.8378\n",
      "Epoch 16/20\n",
      "559s - loss: 0.6268 - acc: 0.8893 - val_loss: 0.8288 - val_acc: 0.8301\n",
      "Epoch 17/20\n",
      "561s - loss: 0.6279 - acc: 0.8904 - val_loss: 1.2768 - val_acc: 0.7219\n",
      "Epoch 18/20\n",
      "561s - loss: 0.6248 - acc: 0.8920 - val_loss: 0.9362 - val_acc: 0.8015\n",
      "Epoch 19/20\n",
      "561s - loss: 0.6184 - acc: 0.8941 - val_loss: 0.9204 - val_acc: 0.8181\n",
      "Epoch 20/20\n",
      "561s - loss: 0.6254 - acc: 0.8915 - val_loss: 1.0211 - val_acc: 0.7706\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04f55fcb00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "556s - loss: 0.5141 - acc: 0.9320 - val_loss: 0.5652 - val_acc: 0.9165\n",
      "Epoch 2/40\n",
      "560s - loss: 0.4530 - acc: 0.9477 - val_loss: 0.5451 - val_acc: 0.9199\n",
      "Epoch 3/40\n",
      "560s - loss: 0.4290 - acc: 0.9546 - val_loss: 0.5409 - val_acc: 0.9188\n",
      "Epoch 4/40\n",
      "559s - loss: 0.4101 - acc: 0.9584 - val_loss: 0.5259 - val_acc: 0.9224\n",
      "Epoch 5/40\n",
      "549s - loss: 0.3934 - acc: 0.9620 - val_loss: 0.5365 - val_acc: 0.9198\n",
      "Epoch 6/40\n",
      "551s - loss: 0.3813 - acc: 0.9631 - val_loss: 0.5150 - val_acc: 0.9209\n",
      "Epoch 7/40\n",
      "556s - loss: 0.3685 - acc: 0.9644 - val_loss: 0.5238 - val_acc: 0.9197\n",
      "Epoch 8/40\n",
      "556s - loss: 0.3565 - acc: 0.9668 - val_loss: 0.5188 - val_acc: 0.9204\n",
      "Epoch 9/40\n",
      "555s - loss: 0.3430 - acc: 0.9693 - val_loss: 0.5078 - val_acc: 0.9206\n",
      "Epoch 10/40\n",
      "553s - loss: 0.3325 - acc: 0.9707 - val_loss: 0.5107 - val_acc: 0.9191\n",
      "Epoch 11/40\n",
      "556s - loss: 0.3220 - acc: 0.9721 - val_loss: 0.5091 - val_acc: 0.9191\n",
      "Epoch 12/40\n",
      "556s - loss: 0.3121 - acc: 0.9738 - val_loss: 0.5033 - val_acc: 0.9212\n",
      "Epoch 13/40\n",
      "556s - loss: 0.3082 - acc: 0.9723 - val_loss: 0.4970 - val_acc: 0.9226\n",
      "Epoch 14/40\n",
      "556s - loss: 0.2986 - acc: 0.9749 - val_loss: 0.5553 - val_acc: 0.9058\n",
      "Epoch 15/40\n",
      "555s - loss: 0.2913 - acc: 0.9746 - val_loss: 0.5065 - val_acc: 0.9203\n",
      "Epoch 16/40\n",
      "552s - loss: 0.2824 - acc: 0.9762 - val_loss: 0.4912 - val_acc: 0.9218\n",
      "Epoch 17/40\n",
      "554s - loss: 0.2774 - acc: 0.9764 - val_loss: 0.5191 - val_acc: 0.9125\n",
      "Epoch 18/40\n",
      "554s - loss: 0.2722 - acc: 0.9769 - val_loss: 0.5023 - val_acc: 0.9184\n",
      "Epoch 19/40\n",
      "550s - loss: 0.2654 - acc: 0.9771 - val_loss: 0.4965 - val_acc: 0.9183\n",
      "Epoch 20/40\n",
      "547s - loss: 0.2603 - acc: 0.9778 - val_loss: 0.5552 - val_acc: 0.9061\n",
      "Epoch 21/40\n",
      "547s - loss: 0.2549 - acc: 0.9779 - val_loss: 0.4868 - val_acc: 0.9168\n",
      "Epoch 22/40\n",
      "547s - loss: 0.2494 - acc: 0.9793 - val_loss: 0.4754 - val_acc: 0.9242\n",
      "Epoch 23/40\n",
      "547s - loss: 0.2462 - acc: 0.9785 - val_loss: 0.5014 - val_acc: 0.9136\n",
      "Epoch 24/40\n",
      "548s - loss: 0.2427 - acc: 0.9792 - val_loss: 0.5226 - val_acc: 0.9075\n",
      "Epoch 25/40\n",
      "547s - loss: 0.2376 - acc: 0.9794 - val_loss: 0.4829 - val_acc: 0.9159\n",
      "Epoch 26/40\n",
      "547s - loss: 0.2325 - acc: 0.9800 - val_loss: 0.5066 - val_acc: 0.9125\n",
      "Epoch 27/40\n",
      "548s - loss: 0.2312 - acc: 0.9790 - val_loss: 0.4887 - val_acc: 0.9155\n",
      "Epoch 28/40\n",
      "548s - loss: 0.2277 - acc: 0.9792 - val_loss: 0.4959 - val_acc: 0.9107\n",
      "Epoch 29/40\n",
      "547s - loss: 0.2255 - acc: 0.9788 - val_loss: 0.6025 - val_acc: 0.8956\n",
      "Epoch 30/40\n",
      "548s - loss: 0.2216 - acc: 0.9798 - val_loss: 0.4708 - val_acc: 0.9180\n",
      "Epoch 31/40\n",
      "548s - loss: 0.2238 - acc: 0.9772 - val_loss: 0.5193 - val_acc: 0.9084\n",
      "Epoch 32/40\n",
      "548s - loss: 0.2174 - acc: 0.9790 - val_loss: 0.5216 - val_acc: 0.9100\n",
      "Epoch 33/40\n",
      "547s - loss: 0.2176 - acc: 0.9782 - val_loss: 0.4960 - val_acc: 0.9153\n",
      "Epoch 34/40\n",
      "548s - loss: 0.2128 - acc: 0.9790 - val_loss: 0.4644 - val_acc: 0.9188\n",
      "Epoch 35/40\n",
      "548s - loss: 0.2113 - acc: 0.9795 - val_loss: 0.4759 - val_acc: 0.9196\n",
      "Epoch 36/40\n",
      "547s - loss: 0.2090 - acc: 0.9789 - val_loss: 0.5176 - val_acc: 0.9066\n",
      "Epoch 37/40\n",
      "548s - loss: 0.2078 - acc: 0.9802 - val_loss: 0.4602 - val_acc: 0.9208\n",
      "Epoch 38/40\n",
      "547s - loss: 0.2112 - acc: 0.9772 - val_loss: 0.4998 - val_acc: 0.9096\n",
      "Epoch 39/40\n",
      "548s - loss: 0.2051 - acc: 0.9794 - val_loss: 0.5156 - val_acc: 0.9066\n",
      "Epoch 40/40\n",
      "547s - loss: 0.2046 - acc: 0.9781 - val_loss: 0.4961 - val_acc: 0.9108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04f5497d30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 40, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "547s - loss: 0.1885 - acc: 0.9845 - val_loss: 0.4287 - val_acc: 0.9256\n",
      "Epoch 2/20\n",
      "548s - loss: 0.1772 - acc: 0.9886 - val_loss: 0.4198 - val_acc: 0.9279\n",
      "Epoch 3/20\n",
      "547s - loss: 0.1734 - acc: 0.9901 - val_loss: 0.4181 - val_acc: 0.9283\n",
      "Epoch 4/20\n",
      "547s - loss: 0.1706 - acc: 0.9910 - val_loss: 0.4188 - val_acc: 0.9280\n",
      "Epoch 5/20\n",
      "548s - loss: 0.1679 - acc: 0.9918 - val_loss: 0.4127 - val_acc: 0.9298\n",
      "Epoch 6/20\n",
      "548s - loss: 0.1670 - acc: 0.9921 - val_loss: 0.4159 - val_acc: 0.9301\n",
      "Epoch 7/20\n",
      "548s - loss: 0.1650 - acc: 0.9926 - val_loss: 0.4139 - val_acc: 0.9300\n",
      "Epoch 8/20\n",
      "547s - loss: 0.1631 - acc: 0.9933 - val_loss: 0.4087 - val_acc: 0.9304\n",
      "Epoch 9/20\n",
      "548s - loss: 0.1619 - acc: 0.9934 - val_loss: 0.4150 - val_acc: 0.9302\n",
      "Epoch 10/20\n",
      "547s - loss: 0.1609 - acc: 0.9939 - val_loss: 0.4154 - val_acc: 0.9294\n",
      "Epoch 11/20\n",
      "547s - loss: 0.1611 - acc: 0.9933 - val_loss: 0.4102 - val_acc: 0.9310\n",
      "Epoch 12/20\n",
      "547s - loss: 0.1584 - acc: 0.9943 - val_loss: 0.4105 - val_acc: 0.9306\n",
      "Epoch 13/20\n",
      "547s - loss: 0.1594 - acc: 0.9934 - val_loss: 0.4093 - val_acc: 0.9309\n",
      "Epoch 14/20\n",
      "547s - loss: 0.1582 - acc: 0.9940 - val_loss: 0.4110 - val_acc: 0.9298\n",
      "Epoch 15/20\n",
      "547s - loss: 0.1567 - acc: 0.9942 - val_loss: 0.4080 - val_acc: 0.9315\n",
      "Epoch 16/20\n",
      "547s - loss: 0.1565 - acc: 0.9940 - val_loss: 0.4113 - val_acc: 0.9304\n",
      "Epoch 17/20\n",
      "548s - loss: 0.1558 - acc: 0.9942 - val_loss: 0.4093 - val_acc: 0.9292\n",
      "Epoch 18/20\n",
      "548s - loss: 0.1561 - acc: 0.9939 - val_loss: 0.4079 - val_acc: 0.9310\n",
      "Epoch 19/20\n",
      "548s - loss: 0.1552 - acc: 0.9942 - val_loss: 0.4153 - val_acc: 0.9297\n",
      "Epoch 20/20\n",
      "547s - loss: 0.1535 - acc: 0.9951 - val_loss: 0.4069 - val_acc: 0.9313\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05ec7ea6a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "548s - loss: 0.1819 - acc: 0.9842 - val_loss: 0.4929 - val_acc: 0.9092\n",
      "Epoch 2/10\n",
      "547s - loss: 0.2018 - acc: 0.9751 - val_loss: 0.5761 - val_acc: 0.8880\n",
      "Epoch 3/10\n",
      "548s - loss: 0.2046 - acc: 0.9742 - val_loss: 0.5411 - val_acc: 0.8950\n",
      "Epoch 4/10\n",
      "548s - loss: 0.2008 - acc: 0.9765 - val_loss: 0.5607 - val_acc: 0.8957\n",
      "Epoch 5/10\n",
      "548s - loss: 0.1956 - acc: 0.9778 - val_loss: 0.4991 - val_acc: 0.9049\n",
      "Epoch 6/10\n",
      "548s - loss: 0.1996 - acc: 0.9760 - val_loss: 0.4714 - val_acc: 0.9112\n",
      "Epoch 7/10\n",
      "548s - loss: 0.1947 - acc: 0.9779 - val_loss: 0.5921 - val_acc: 0.8855\n",
      "Epoch 8/10\n",
      "547s - loss: 0.1958 - acc: 0.9770 - val_loss: 0.5096 - val_acc: 0.9058\n",
      "Epoch 9/10\n",
      "547s - loss: 0.1976 - acc: 0.9754 - val_loss: 0.5129 - val_acc: 0.9041\n",
      "Epoch 10/10\n",
      "548s - loss: 0.1940 - acc: 0.9767 - val_loss: 0.5693 - val_acc: 0.8869\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04f52ac668>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 10, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "548s - loss: 0.1879 - acc: 0.9801 - val_loss: 0.4073 - val_acc: 0.9270\n",
      "Epoch 2/20\n",
      "548s - loss: 0.1631 - acc: 0.9893 - val_loss: 0.4040 - val_acc: 0.9265\n",
      "Epoch 3/20\n",
      "547s - loss: 0.1601 - acc: 0.9905 - val_loss: 0.4007 - val_acc: 0.9295\n",
      "Epoch 4/20\n",
      "547s - loss: 0.1560 - acc: 0.9919 - val_loss: 0.4016 - val_acc: 0.9294\n",
      "Epoch 5/20\n",
      "548s - loss: 0.1540 - acc: 0.9921 - val_loss: 0.3988 - val_acc: 0.9293\n",
      "Epoch 6/20\n",
      "547s - loss: 0.1529 - acc: 0.9926 - val_loss: 0.4013 - val_acc: 0.9283\n",
      "Epoch 7/20\n",
      "548s - loss: 0.1497 - acc: 0.9937 - val_loss: 0.3984 - val_acc: 0.9312\n",
      "Epoch 8/20\n",
      "548s - loss: 0.1508 - acc: 0.9929 - val_loss: 0.3993 - val_acc: 0.9304\n",
      "Epoch 9/20\n",
      "547s - loss: 0.1486 - acc: 0.9937 - val_loss: 0.3988 - val_acc: 0.9303\n",
      "Epoch 10/20\n",
      "547s - loss: 0.1471 - acc: 0.9938 - val_loss: 0.3978 - val_acc: 0.9302\n",
      "Epoch 11/20\n",
      "547s - loss: 0.1460 - acc: 0.9942 - val_loss: 0.3945 - val_acc: 0.9306\n",
      "Epoch 12/20\n",
      "547s - loss: 0.1453 - acc: 0.9943 - val_loss: 0.3988 - val_acc: 0.9292\n",
      "Epoch 13/20\n",
      "547s - loss: 0.1456 - acc: 0.9939 - val_loss: 0.4004 - val_acc: 0.9298\n",
      "Epoch 14/20\n",
      "547s - loss: 0.1434 - acc: 0.9946 - val_loss: 0.3978 - val_acc: 0.9314\n",
      "Epoch 15/20\n",
      "547s - loss: 0.1427 - acc: 0.9946 - val_loss: 0.3974 - val_acc: 0.9311\n",
      "Epoch 16/20\n",
      "547s - loss: 0.1417 - acc: 0.9949 - val_loss: 0.3978 - val_acc: 0.9320\n",
      "Epoch 17/20\n",
      "548s - loss: 0.1403 - acc: 0.9954 - val_loss: 0.4010 - val_acc: 0.9317\n",
      "Epoch 18/20\n",
      "548s - loss: 0.1395 - acc: 0.9955 - val_loss: 0.3989 - val_acc: 0.9324\n",
      "Epoch 19/20\n",
      "547s - loss: 0.1409 - acc: 0.9951 - val_loss: 0.3997 - val_acc: 0.9312\n",
      "Epoch 20/20\n",
      "548s - loss: 0.1402 - acc: 0.9948 - val_loss: 0.3973 - val_acc: 0.9323\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04f5264588>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 s, sys: 452 ms, total: 31.6 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%time model.save_weights('models/93.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
