{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# En<->Fr translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jhoward/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path='/data/jhoward/datasets/fr-en-109-corpus/'\n",
    "dpath = 'data/translate/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Prepare corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname=path+'giga-fren.release2.fixed'\n",
    "en_fname = fname+'.en'\n",
    "fr_fname = fname+'.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname), open(fr_fname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]\n",
    "len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       " ('Who are we?', 'Où sommes-nous?'),\n",
       " ('Where did we come from?', \"D'où venons-nous?\"),\n",
       " ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       " ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "  'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?'),\n",
       " ('What is the major aboriginal group on Vancouver Island?',\n",
       "  'Quel est le groupe autochtone principal sur l’île de Vancouver?')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dump(qs, dpath+'qs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qs = load(dpath+'qs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "en_qs, fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "re_mult_space = re.compile(r\"  *\")\n",
    "re_mw_punc = re.compile(r\"(\\w[’'])(\\w)\")\n",
    "re_punc = re.compile(\"([\\\"().,;:/_?!—])\")\n",
    "re_apos = re.compile(r\"(\\w)'s\\b\")\n",
    "\n",
    "def simple_toks(sent):\n",
    "    sent = re_apos.sub(r\"\\1 's\", sent)\n",
    "    sent = re_mw_punc.sub(r\"\\1 \\2\", sent)\n",
    "    sent = re_punc.sub(r\" \\1 \", sent).replace('-', ' ')\n",
    "    sent = re_mult_space.sub(' ', sent)\n",
    "    return sent.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['qu’', 'est', 'ce', 'que', 'la', 'lumière', '?'],\n",
       " ['où', 'sommes', 'nous', '?'],\n",
       " [\"d'\", 'où', 'venons', 'nous', '?'],\n",
       " ['que', 'ferions', 'nous', 'sans', 'elle', '?']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_qtoks = list(map(simple_toks, fr_qs)); fr_qtoks[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'light', '?'],\n",
       " ['who', 'are', 'we', '?'],\n",
       " ['where', 'did', 'we', 'come', 'from', '?'],\n",
       " ['what', 'would', 'we', 'do', 'without', 'it', '?']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_qtoks = list(map(simple_toks, en_qs)); en_qtoks[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rachel', \"'s\", 'baby', 'is', 'cuter', 'than', 'other', \"'s\", '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_toks(\"Rachel's baby is cuter than other's.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "SOS = 1\n",
    "\n",
    "def toks2ids(sents):\n",
    "    voc_cnt = collections.Counter(t for sent in sents for t in sent)\n",
    "    vocab = sorted(voc_cnt, key=voc_cnt.get, reverse=True)\n",
    "    vocab.insert(PAD, \"<PAD>\")\n",
    "    vocab.insert(SOS, \"<SOS>\")\n",
    "    w2id = {w:i for i,w in enumerate(vocab)}\n",
    "    ids = [[w2id[t] for t in sent] for sent in sents]\n",
    "    return ids, vocab, w2id, voc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fr_ids, fr_vocab, fr_w2id, fr_counts = toks2ids(fr_qtoks)\n",
    "en_ids, en_vocab, en_w2id, en_counts = toks2ids(en_qtoks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "en_vecs, en_wv_word, en_wv_idx = load_glove(\n",
    "    '/data/jhoward/datasets/nlp/glove/results/6B.100d')\n",
    "en_w2v = {w: en_vecs[en_wv_idx[w]] for w in en_wv_word}\n",
    "n_en_vec, dim_en_vec = en_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fr_wik = pickle.load(open('/data/jhoward/datasets/nlp/polyglot-fr.pkl', 'rb'), \n",
    "#                      encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "source": [
    "From http://fauconnier.github.io/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w2v_path='/data/jhoward/datasets/nlp/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin'\n",
    "fr_model = word2vec.Word2Vec.load_word2vec_format(w2v_path, binary=True)\n",
    "fr_voc = fr_model.vocab\n",
    "dim_fr_vec = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_emb(w2v, targ_vocab, dim_vec):\n",
    "    vocab_size = len(targ_vocab)\n",
    "    emb = np.zeros((vocab_size, dim_vec))\n",
    "    found=0\n",
    "\n",
    "    for i, word in enumerate(targ_vocab):\n",
    "        try: emb[i] = w2v[word]; found+=1\n",
    "        except KeyError: emb[i] = normal(scale=0.6, size=(dim_vec,))\n",
    "\n",
    "    return emb, found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19549, 100), 17201)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_embs, found = create_emb(en_w2v, en_vocab, dim_en_vec); en_embs.shape, found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26709, 200), 21878)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_embs, found = create_emb(fr_model, fr_vocab, dim_fr_vec); fr_embs.shape, found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52331, 30), (52331, 30), (19549, 100))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 30\n",
    "en_padded = pad_sequences(en_ids, maxlen, 'int64', \"post\", \"post\")\n",
    "fr_padded = pad_sequences(fr_ids, maxlen, 'int64', \"post\", \"post\")\n",
    "en_padded.shape, fr_padded.shape, en_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fr_train, fr_test, en_train, en_test = sklearn.model_selection.train_test_split(\n",
    "    fr_padded, en_padded, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47097, 30), (5234, 30), (47097, 30), (5234, 30)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in (fr_train, fr_test, en_train, en_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  35,   15,   10,   20,    8,  261,    7,    8, 2777,  668,    9,\n",
       "           5,  290,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([   4,   36,   68,    7,  323, 2203,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_train[0], en_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size=16):\n",
    "    idxs = np.random.permutation(len(x))[:batch_size]\n",
    "    return x[idxs], y[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Var(*sz): return Variable(Arr(*sz), requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Arr(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "\n",
    "def unit_prefix(x, n=1):\n",
    "    for i in range(n): x = x.unsqueeze(0)\n",
    "    return x\n",
    "\n",
    "def align(x, y, start_dim=2):\n",
    "    xd, yd = x.dim(), y.dim()\n",
    "    if xd > yd: y = unit_prefix(y, xd - yd)\n",
    "    elif yd > xd: x = unit_prefix(x, yd - xd)\n",
    "\n",
    "    xs, ys = list(x.size()), list(y.size())\n",
    "    nd = len(ys)\n",
    "    for i in range(start_dim, nd):\n",
    "        td = nd-i-1\n",
    "        if   ys[td]==1: ys[td] = xs[td]\n",
    "        elif xs[td]==1: xs[td] = ys[td]\n",
    "    return x.expand(*xs), y.expand(*ys)\n",
    "\n",
    "def dot(x, y):\n",
    "    assert(1<y.dim()<5)\n",
    "    x, y = align(x, y)\n",
    "    \n",
    "    if y.dim() == 2: return x.mm(y)\n",
    "    elif y.dim() == 3: return x.bmm(y)\n",
    "    else:\n",
    "        xs,ys = x.size(), y.size()\n",
    "        res = torch.zeros(*(xs[:-1] + (ys[-1],)))\n",
    "        for i in range(xs[0]): res[i].baddbmm_(x[i], (y[i]))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def aligned_op(x,y,f): return f(*align(x,y,0))\n",
    "\n",
    "def add(x, y): return aligned_op(x, y, operator.add)\n",
    "def sub(x, y): return aligned_op(x, y, operator.sub)\n",
    "def mul(x, y): return aligned_op(x, y, operator.mul)\n",
    "def div(x, y): return aligned_op(x, y, operator.truediv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = Arr(3, 2)\n",
    "m2 = Arr(4, 3)\n",
    "v = Arr(2)\n",
    "b = Arr(4,3,2)\n",
    "t = Arr(5,4,3,2)\n",
    "\n",
    "mt = m.transpose(0,1)\n",
    "bt = b.transpose(1,2)\n",
    "tt = t.transpose(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_eq(x,y): assert(torch.equal(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_eq(dot(m,mt),m.mm(mt))\n",
    "check_eq(dot(v,mt), v.unsqueeze(0).mm(mt))\n",
    "check_eq(dot(b,bt),b.bmm(bt))\n",
    "check_eq(dot(b,mt),b.bmm(unit_prefix(mt).expand_as(bt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "exp = t.view(-1,3,2).bmm(tt.contiguous().view(-1,2,3)).view(5,4,3,3)\n",
    "check_eq(dot(t,tt),exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_eq(add(m,v),m+unit_prefix(v).expand_as(m))\n",
    "check_eq(add(v,m),m+unit_prefix(v).expand_as(m))\n",
    "check_eq(add(m,t),t+unit_prefix(m,2).expand_as(t))\n",
    "check_eq(sub(m,v),m-unit_prefix(v).expand_as(m))\n",
    "check_eq(mul(m,v),m*unit_prefix(v).expand_as(m))\n",
    "check_eq(div(m,v),m/unit_prefix(v).expand_as(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_emb(emb_mat, non_trainable=False):\n",
    "    output_size, emb_size = emb_mat.size()\n",
    "    emb = nn.Embedding(output_size, emb_size)\n",
    "    emb.load_state_dict({'weight': emb_mat})\n",
    "    if non_trainable:\n",
    "        for param in emb.parameters(): \n",
    "            param.requires_grad = False\n",
    "    return emb, emb_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embs, hidden_size, n_layers=2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.emb, emb_size, output_size = create_emb(embs, True)\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True, num_layers=n_layers)\n",
    "#                          ,bidirectional=True)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        return self.gru(self.emb(input), hidden)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode(inp, encoder):\n",
    "    batch_size, input_length = inp.size()\n",
    "    hidden = encoder.initHidden(batch_size).cuda()\n",
    "    enc_outputs, hidden = encoder(inp, hidden)\n",
    "    return long_t([SOS]*batch_size), enc_outputs, hidden    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embs, hidden_size, n_layers=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.emb, emb_size, output_size = create_emb(embs)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True, num_layers=n_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        emb = self.emb(inp).unsqueeze(1)\n",
    "        res, hidden = self.gru(emb, hidden)\n",
    "        res = F.log_softmax(self.out(res[:,0]))\n",
    "        return res, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, embs, hidden_size, n_layers=2, p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.emb, emb_size, output_size = create_emb(embs)\n",
    "        self.W1 = Var(hidden_size, hidden_size)\n",
    "        self.W2 = Var(hidden_size, hidden_size)\n",
    "        self.W3 = Var(emb_size+hidden_size, hidden_size)\n",
    "        self.b2 = Var(hidden_size)\n",
    "        self.b3 = Var(hidden_size)\n",
    "        self.V = Var(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inp, hidden, enc_outputs):\n",
    "        emb_inp = self.emb(inp)\n",
    "        # Can calc this once per seq and save:\n",
    "        w1e = dot(enc_outputs, self.W1)\n",
    "        w2h = add(dot(hidden[-1], self.W2), self.b2).unsqueeze(1)\n",
    "        u = F.tanh(add(w1e, w2h))\n",
    "        a = mul(self.V,u).sum(2).squeeze(2)\n",
    "        a = F.softmax(a).unsqueeze(2)\n",
    "        Xa = mul(a, enc_outputs).sum(1)\n",
    "        res = dot(torch.cat([emb_inp, Xa.squeeze(1)], 1), self.W3)\n",
    "        res = add(res, self.b3).unsqueeze(0)\n",
    "        res, hidden = self.gru(res, hidden)\n",
    "        res = F.log_softmax(self.out(res.squeeze(0)))\n",
    "        return res, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Attention testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "fra, eng = get_batch(fr_train, en_train, 4)\n",
    "inp = long_t(fra)\n",
    "targ = long_t(eng)\n",
    "emb, emb_size, output_size = create_emb(en_emb_t)\n",
    "emb.cuda()\n",
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W1 = Var(hidden_size, hidden_size)\n",
    "W2 = Var(hidden_size, hidden_size)\n",
    "W3 = Var(emb_size+hidden_size, hidden_size)\n",
    "b2 = Var(1,hidden_size)\n",
    "b3 = Var(1,hidden_size)\n",
    "V = Var(1,1,hidden_size)\n",
    "gru = nn.GRU(hidden_size, hidden_size, num_layers=2).cuda()\n",
    "out = nn.Linear(hidden_size, output_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 30, 128]), torch.Size([2, 4, 128]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inputs, enc_outputs, hidden = encode(inp, encoder)\n",
    "enc_outputs.size(), hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_inp = emb(dec_inputs); emb_inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30, 128])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1e = dot(enc_outputs, W1); w1e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2h = dot(hidden[-1], W2)\n",
    "w2h = (w2h+b2.expand_as(w2h)).unsqueeze(1); w2h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 30, 1]), Variable containing:\n",
       "  1.0000\n",
       "  1.0000\n",
       "  1.0000\n",
       "  1.0000\n",
       " [torch.cuda.FloatTensor of size 4x1 (GPU 0)])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = F.tanh(w1e + w2h.expand_as(w1e))\n",
    "a = (V.expand_as(u)*u).sum(2).squeeze(2)\n",
    "a = F.softmax(a).unsqueeze(2); a.size(),a.sum(1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa = (a.expand_as(enc_outputs) * enc_outputs).sum(1); Xa.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = dot(torch.cat([emb_inp, Xa.squeeze(1)], 1), W3)\n",
    "res = (res+b3.expand_as(res)).unsqueeze(0); res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 128]), torch.Size([2, 4, 128]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, hidden = gru(res, hidden); res.size(), hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 19549])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = F.log_softmax(out(res.squeeze(0))); res.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def long_t(arr): return Variable(torch.LongTensor(arr)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(inp, targ, encoder, decoder, enc_opt, dec_opt, crit):\n",
    "    decoder_input, encoder_outputs, hidden = encode(inp, encoder)\n",
    "    target_length = targ.size()[1]\n",
    "    \n",
    "    enc_opt.zero_grad(); dec_opt.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "        decoder_input = targ[:, di]\n",
    "        loss += crit(decoder_output, decoder_input)\n",
    "\n",
    "    loss.backward()\n",
    "    enc_opt.step(); dec_opt.step()\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def req_grad_params(o):\n",
    "    return (p for p in o.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, n_epochs, print_every=1000, lr=0.01):\n",
    "    loss_total = 0 # Reset every print_every\n",
    "    \n",
    "    enc_opt = optim.RMSprop(req_grad_params(encoder), lr=lr)\n",
    "    dec_opt = optim.RMSprop(decoder.parameters(), lr=lr)\n",
    "    crit = nn.NLLLoss().cuda()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        fra, eng = get_batch(fr_train, en_train, 64)\n",
    "        inp = long_t(fra)\n",
    "        targ = long_t(eng)\n",
    "        loss = train(inp, targ, encoder, decoder, enc_opt, dec_opt, crit)\n",
    "        loss_total += loss\n",
    "\n",
    "        if epoch % print_every == print_every-1:\n",
    "            print('%d %d%% %.4f' % (epoch, epoch / n_epochs * 100, loss_total / print_every))\n",
    "            loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fr_emb_t = torch.FloatTensor(fr_embs).cuda()\n",
    "en_emb_t = torch.FloatTensor(en_embs).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "encoder = EncoderRNN(fr_emb_t, hidden_size).cuda()\n",
    "decoder = AttnDecoderRNN(en_emb_t, hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 9% 1.6918\n",
      "99 19% 1.5436\n",
      "149 29% 1.5169\n",
      "199 39% 1.4880\n",
      "249 49% 1.4782\n",
      "299 59% 1.4430\n",
      "349 69% 1.4048\n",
      "399 79% 1.3791\n",
      "449 89% 1.3803\n",
      "499 99% 1.3600\n"
     ]
    }
   ],
   "source": [
    "trainEpochs(encoder, decoder, 500, print_every=50, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 4% 2.2873\n",
      "999 9% 1.9017\n",
      "1499 14% 1.7423\n",
      "1999 19% 1.6179\n",
      "2499 24% 1.5296\n",
      "2999 29% 1.4666\n",
      "3499 34% 1.4053\n",
      "3999 39% 1.3579\n",
      "4499 44% 1.3248\n",
      "4999 49% 1.2850\n",
      "5499 54% 1.2461\n",
      "5999 59% 1.2263\n",
      "6499 64% 1.2016\n",
      "6999 69% 1.1713\n",
      "7499 74% 1.1481\n",
      "7999 79% 1.1374\n",
      "8499 84% 1.1205\n",
      "8999 89% 1.1070\n",
      "9499 94% 1.0914\n",
      "9999 99% 1.0760\n"
     ]
    }
   ],
   "source": [
    "trainEpochs(encoder, decoder, 10000, print_every=500, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(inp):\n",
    "    decoder_input, encoder_outputs, hidden = encode(inp, encoder)\n",
    "    target_length = maxlen\n",
    "\n",
    "    decoded_words = []\n",
    "    for di in range(target_length):\n",
    "        decoder_output, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni==PAD: break\n",
    "        decoded_words.append(en_vocab[ni])\n",
    "        decoder_input = long_t([ni])\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sent2ids(sent):\n",
    "    ids = [fr_w2id[t] for t in simple_toks(sent)]\n",
    "    return pad_sequences([ids], maxlen, 'int64', \"post\", \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fr2en(sent): \n",
    "    ids = long_t(sent2ids(sent))\n",
    "    trans = evaluate(ids)\n",
    "    return ' '.join(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the population of Canada? Quelle est la population du Canada ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"what is canada 's population ?\""
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=8\n",
    "print(en_qs[i],fr_qs[i])\n",
    "fr2en(fr_qs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
